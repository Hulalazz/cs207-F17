{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 15\n",
    "\n",
    "### Monday, October 30th 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generators\n",
    "\n",
    "* A generator function looks like a normal function, but yields values instead of returning them. \n",
    "* The syntax is (unfortunately) the same otherwise ([PEP 255 -- Simple Generators](https://www.python.org/dev/peps/pep-0255/)).\n",
    "* A generator is a different beast. When the function runs, it creates a generator.\n",
    "* The generator is an iterator and gets an internal implementation of `__iter__` and `__next__`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* When `next` is called on the generator, the function proceeds until the first yield.\n",
    "* The function body is now suspended and the value in the yield is then passed to the calling scope as the outcome of the `next`.\n",
    "* When next is called again, it gets `__next__` called again (implicitly) in the generator, and the next value is yielded.\n",
    "* This continues until we reach the end of the function, the return of which creates a `StopIteration` in next.\n",
    "\n",
    "Any Python function that has the yield keyword in its body is a generator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary\n",
      "had\n",
      "a\n",
      "little\n",
      "lamb\n",
      "whose\n",
      "fleece\n",
      "was\n",
      "white\n",
      "as\n",
      "snow.\n"
     ]
    }
   ],
   "source": [
    "# it = iter(a) #it is an iterator\n",
    "# while True:\n",
    "#     try:\n",
    "#         nextval = next(it)\n",
    "#         print(nextval)\n",
    "#     except StopIteration:\n",
    "#         del it\n",
    "#         break\n",
    "for w in a:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "def mygen(N):\n",
    "    for i in range(N):\n",
    "        yield i**2\n",
    "\n",
    "for vals in mygen(7):\n",
    "    print(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise 1\n",
    "Fibonacci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fibgen(N):\n",
    "    for i in range(1,N+1):\n",
    "        if i < 2:\n",
    "            yield 1\n",
    "        else:\n",
    "            yield "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Recall the `Sentence` iterator class:\n",
    "\n",
    "```python\n",
    "class SentenceIterator:\n",
    "    def __init__(self, words): \n",
    "        self.words = words \n",
    "        self.index = 0\n",
    "        \n",
    "    def __next__(self): \n",
    "        try:\n",
    "            word = self.words[self.index] \n",
    "        except IndexError:\n",
    "            raise StopIteration() \n",
    "        self.index += 1\n",
    "        return word \n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "class Sentence: # An iterable\n",
    "    def __init__(self, text): \n",
    "        self.text = text\n",
    "        self.words = text.split()\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return SentenceIterator(self.words)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Sentence(%s)' % reprlib.repr(self.text)\n",
    "```\n",
    "\n",
    "Create a `Sentence` iterator class that uses a generator expression.  You will write the generator expression in the `__iter__` special method.  Note that the generator automatically gets `__next__`.  As a result, you only need to create a single class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How Things Work\n",
    "We've introduced some data structures and discussed why they're important.\n",
    "\n",
    "Now we'll go over where things live in the computer and how `Python` actually does things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Process address space\n",
    "\n",
    "What do we mean when we say a program is \"in memory\"?\n",
    "\n",
    "- compiled code must be loaded from disk into memory. \n",
    "- once your program starts, it must create (reserve) space for the variables it will use and it must store and read values from those variables. \n",
    "\n",
    "The code, the reserved space, and the generated data all constitute a program's memory footprint.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Every operating system has a (different) convention for exactly where and how these different resources are actually laid out in memory. These conventions are called *object file formats*.\n",
    "\n",
    "In Linux, the most common object format is called `ELF`, short for \"Executable and Linkable Format\".\n",
    "\n",
    "![](./segments.png)\n",
    "\n",
    "A simplified view of our example program looks like this in memory: the `stack` and the `heap`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Stack\n",
    "\n",
    "The stack keeps track of function calls and their data. \n",
    "\n",
    "- Whenever a function is called, a new chunk of memory is reserved at the top of the stack in order to store variables for that function. \n",
    "- This includes variables that you have defined inside your function and function parameters, but it also includes data that were generated automatically by the compiler. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The most recognizable value in this latter category is the return address. When a function calls `return`, the computer starts executing instructions at the location that the function was originally called from.\n",
    "- When a function returns, it removes its stack frame from the stack. This means that at any given point, the stack contains a record of which functions the program is currently in.\n",
    "- Removing the function stack from from the stack becomes a problem if you want to create space for variables and then access them after the function returns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Heap\n",
    "- The heap is another memory location which is not reclaimed after a function returns. It is explicitly managed, which means that you need to ask to allocate a variable in it. What's more, when you're finished with that space, you need to say so.\n",
    "- This interface, explicitly requesting and releasing memory from the heap, is typically called *memory management*.\n",
    "- In `C` you do this directly using `malloc`/`free`. Python takes care of this for you using **garbage collection**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How does Python manage memory?\n",
    "So far, when you create a list in `Python` (e.g. `a=[1,2,3,4,5]`), we have been thinking of it as an array of integers.\n",
    "\n",
    "But that is not actually the case.\n",
    "\n",
    "An array would be 5 contiguous integers with some book-keeping at the beginning either on the stack or the heap.\n",
    "\n",
    "You are all highly encouraged to read the eminently readable article [Why Python is Slow](https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/) from Jake Vanderplas's blog.  Most of the following points come from his discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Python` objects are allocated on the heap: an `int` is not an `int`\n",
    "An int is represented in `Python` as a `C` structure **allocated on the heap**.\n",
    "\n",
    "The picture of this C structure looks a little bit like this:\n",
    "\n",
    "![](http://jakevdp.github.io/images/cint_vs_pyint.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On Jake's blog, he shows how this integer is represented:\n",
    "\n",
    "```C\n",
    "struct _longobject {\n",
    "    long ob_refcnt; // in PyObject_HEAD\n",
    "    PyTypeObject *ob_type; // in PyObject_HEAD\n",
    "    size_t ob_size; // in PyObject_HEAD\n",
    "    long ob_digit[1];\n",
    "};\n",
    "```\n",
    "It's not just a simple integer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Boxing and unboxing (or why is `Python` slow)\n",
    "Because `int`s are stored in this scheme, a simple addition involves a lot of work!\n",
    "\n",
    "[Why `Python` is Slow](https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/).\n",
    "\n",
    "    \n",
    "So it's not a simple addition...there is all this machinery around it.\n",
    "\n",
    "And that example was just to add two `int`s where `binary_add` is optimized in C!\n",
    "\n",
    "If these were user defined classes, there would be additional overhead from `dunder` methods for addition!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What About Lists?\n",
    "\n",
    "A python list is represented by this struct:\n",
    "\n",
    "```C\n",
    "typedef struct {\n",
    "    long ob_refcnt;\n",
    "    PyTypeObject *ob_type;\n",
    "    Py_ssize_t ob_size;\n",
    "    PyObject **ob_item;\n",
    "    long allocated;\n",
    "} PyListObject;\n",
    "```\n",
    "\n",
    "Notice the `PyObject**`. This points to the contents of the list. What is this a list of? This is a list of `PyObject*`.\n",
    "\n",
    "Each of those pointers, when dereferenced, gives us an `IntStruct`. The `ob_size` tells us the number of items on the list.\n",
    "\n",
    "Thus this is **an array of pointers to heap allocated `IntStruct`**s.\n",
    "\n",
    "This is illustrated next (`int` 1 means an `IntStruct` with digit 1): [Simple Example](https://goo.gl/jjfpNV)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What do others do?\n",
    "\n",
    "`Julia`:\n",
    ">In the most general case, an array may contain objects of type Any. For most computational purposes, arrays should contain objects of a more specific type, such as Float64 or Int32.\n",
    "\n",
    "```julia\n",
    "a = Real[]    # typeof(a) = Array{Real,1}\n",
    "if (f = rand()) < .8\n",
    "    push!(a, f)\n",
    "end\n",
    "```\n",
    "\n",
    "Because `a` is a an array of abstract type `Real`, it must be able to hold any `Real` value. Since `Real` objects can be of arbitrary size and structure, `a` must be represented as an array of pointers to individually allocated `Real` objects. Because `f` will always be a `Float64`, we should instead, use:\n",
    "\n",
    "```julia\n",
    "a = Float64[] # typeof(a) = Array{Float64,1}\n",
    "```\n",
    "\n",
    "which will create a contiguous block of 64-bit floating-point values that can be manipulated efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`C`:\n",
    "\n",
    "You allocate explicitly either on the heap or stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In `Python` you can append to lists. So what's an `ob_size` doing in our struct then?\n",
    "\n",
    "Turns out Python lists are implemented in something called a dynamic array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Arrays\n",
    "\n",
    "A static array is a contiguous slab of memory of known size, such that `n` items can fit in.  This is a great data structure. Why?\n",
    "\n",
    "- constant time index access: a[i] is O(1)...just seek i*sizeof(int) for example down\n",
    "- linear time traversal or search: 1 unit per loop iteration means O(n) in loop.\n",
    "- locality in memory: its one int after another\n",
    "\n",
    "Tuples in `Python` are fixed size, static arrays.\n",
    "\n",
    "But the big problem is, what if we want to add something more beyond the end of the array? Then we must use dynamic arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dynamic Arrays\n",
    "What `Python` does is first create a fixed size array of these `Pyobject*` pointers on the heap. Then, as you append, it uses its own algorithm to figure out when to expand the size of the array.\n",
    "\n",
    "[`listobject.c`](https://svn.python.org/projects/python/trunk/Objects/listobject.c )\n",
    "\n",
    "```C\n",
    "/* This over-allocates proportional to the list size, making room\n",
    "     * for additional growth.  The over-allocation is mild, but is\n",
    "     * enough to give linear-time amortized behavior over a long\n",
    "     * sequence of appends() in the presence of a poorly-performing\n",
    "     * system realloc().\n",
    "     * The growth pattern is:  0, 4, 8, 16, 25, 35, 46, 58, 72, 88, ...\n",
    "     */\n",
    "new_allocated = (newsize >> 3) + (newsize < 9 ? 3 : 6);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Performance of Dynamic Arrays\n",
    "\n",
    "Lets assume we start with an array of size of $1$ (one slot) and then double the size each time. After $n$ doublings, we have an array with $2^n$ slots.  So, it then takes $lg(n)$ doublings for the array to have $n$ slots (note, $\\lg(n)$ means $\\log_{2}(n)$).\n",
    "\n",
    "Notice that we might not get the continuously allocated memory we want. So we'll have to recopy to a larger array.\n",
    "\n",
    "The last $n/2$ numbers in the array don't move at all (they're the new ones). The previous $n/4$ numbers in the array would have moved once, the previous $n/8$ twice, and so on.\n",
    "\n",
    "Thus the total number of movements is \n",
    "\n",
    "$$ \\sum_{i=1}^{lg(n)} i*\\frac{n}{2^{i+1}}. $$ \n",
    "\n",
    "In the limit as $n\\to\\infty$ we have\n",
    "\n",
    "$$\\frac{n}{2} \\sum_{i=1}^{\\infty} \\frac{i}{2^i} = n.$$\n",
    "\n",
    "This is an amazing result. The work of reallocation is still $O(n)$ on the average, as if a single array had been allocated in advance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Here's the calculation.  Let $x = 1/2$ in what follows.\n",
    "\n",
    "\\begin{align*}\n",
    "  \\sum_{i=0}^{\\infty}{\\left(i+1\\right)x^{i+1}} &= x\\sum_{i=0}^{\\infty}{\\left(i+1\\right)x^{i}} \\\\\n",
    "      &= x\\frac{\\mathrm{d}}{\\mathrm{d}x}\\sum_{i=0}^{\\infty}{x^{i+1}} \\\\\n",
    "      &= x\\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[x\\sum_{i=0}^{\\infty}{x^{i}}\\right] \\\\\n",
    "      &= x\\frac{\\mathrm{d}}{\\mathrm{d}x}\\left[\\frac{x}{1-x}\\right] \\\\\n",
    "      &= \\frac{x}{\\left(1-x\\right)^{2}}.\n",
    "\\end{align*}\n",
    "When $x = 1/2$ we have\n",
    "$$\\frac{x}{\\left(1-x\\right)^{2}} = 2.$$\n",
    "From here we can easily get the result from the previous slide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Containers  vs Flats\n",
    "\n",
    "Earlier we saw how `Python` lists contained references to integer (\"digit\")+metdata based structs on the heap. \n",
    "\n",
    "We call sequences that hold such \"references\" to objects on the heap **Container Sequences**. Examples of such container sequences are `list`, `tuple`, `collections.deque`.\n",
    "\n",
    "There are collections in `Python` which contain contiguous \"typed\" memory (which itself is allocated on the heap). We call these **Flat Sequences**. Such containers in `Python 3` are: `str`, `bytes`, `bytearray`, `memoryview`, `array.array`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You have probably extensively used one of these which is not mentioned yet. This is numpy's ndarray: `np.array`.\n",
    "\n",
    "All of these are faster as they work with **contiguous blocks of uniformly formatted memory**.\n",
    "\n",
    "From Fluent Python:\n",
    "> Container sequences hold references to the objects they contain, which may be of any type, while flat sequences physically store the value of each item within its own memory space, and not as distinct objects. Thus, flat sequences are more compact, but they are limited to holding primitive values like characters, bytes, and numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also a more general way of thinking about data structures. \n",
    "\n",
    ">**Contiguously-allocated** structures are composed of single slabs of memory, and include arrays, matrices, heaps, and hash tables.\n",
    "\n",
    ">**Linked** data structures are composed of distinct chunks of memory bound together by pointers, and include lists, trees, and graph adjacency lists.\n",
    "\n",
    "(Steven S Skiena. The Algorithm Design Manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- A critical advantake of something like a contiguous memory array is that indexing is a constant time operation, as opposed to worst-case O(n), as we saw in linked lists. \n",
    "- Other benefits include a tighter size and a locality of memory which benefits cache and general memory transport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mutable vs Immutable\n",
    "\n",
    "A recurrent theme in this course is that of the mutability of objects. One can also study containers based on their mutability. **Mutable Sequences** in python 3 are:\n",
    "\n",
    "`list, bytearray, array.array, collections.deque, memoryview`\n",
    "\n",
    "whereas immutable seuqnces in Python 3 are\n",
    "\n",
    "`tuple, str, bytes`\n",
    "\n",
    "Lets learn about some of these collections in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### array.array\n",
    "\n",
    "The list type is nice and very flexible, but if you need to store many many (millions) of floating point variables, array.array is a better option. It stores just the bytes representing the type, so its just like a contiguous C array of things in RAM, and also just like a numpy array. \n",
    "\n",
    "`array.array` IS mutable, and you dont need to allocate ahead of time (reallocation will be done).\n",
    "\n",
    "The constructor is: \n",
    "\n",
    "`array(typecode [, initializer]) -- create a new array`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from array import array\n",
    "from random import random\n",
    "#generator expression instead of list comprehension\n",
    "floats_aa=array('d', (random() for i in range(10**8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floats_aa.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array.array, 0.5667536435553536)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(floats_aa), floats_aa[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "floats_list=[random() for i in range(10**8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some behavior that you see might be unexpected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.88 s, sys: 424 ms, total: 3.31 s\n",
      "Wall time: 3.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for f in floats_aa:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.27 s, sys: 3.36 s, total: 6.63 s\n",
      "Wall time: 8.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for f in floats_list:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so a regular python list on 100 million floats only costs double. Why would you use `array.array` then? And Why is accessing floats in an `array.array` so slow. The answer to the latter is that in using the standard python access, like in a `for` loop each float is **boxed** by the python runtime. You saw this earlier!\n",
    "\n",
    "Remember the int based structs we had earlier? In an `array.array` or in `numpy` for that matter, when you \"iterate\" over the array, and use the ints you get, what python does is to take that 32 bits or 64 bits from memory, wrap it up into one of these structs, and hand it to you. You asked for a python int after all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What it also means is that ops on `array.array` which can be done with C are fast, but access into python is slow. \n",
    "\n",
    "This is why `numpy.ndarray` is written in C, with ops like `numpy.dot` written in C as well. (None of the `array.array` functionality is exposed with any complex operations under the hood, so its current use remains limited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you want to use numerical stuff, use `numpy` arrays. But `array.array`s are still useful when a buffer needs to be shlepped between Python and C, for quick access to things. If you are using legacy code in C which ops on these lists, this is the way to do it fast. Indeed, otherwise lists can be faster because of this \"boxing\" penalty. (see https://www.python.org/doc/essays/list2str/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### memoryviews\n",
    "\n",
    "Memoryviews, inspired by numpy and scipy, let you handle slices of arrays without expensively copying bytes.\n",
    "\n",
    "Travis Oliphant, as quoted in Fluent:\n",
    ">A memoryview is essentially a generalized NumPy array structure in Python itself (without the math). It allows you to share memory between data-structures (things like PIL images, SQLlite databases, NumPy arrays, etc.) without first copying. This is very important for large data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(int, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import array\n",
    "numbers = array.array('h', [-2, -1, 0, 1, 2])#short signed ints\n",
    "type(numbers[0]), numbers.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<memory at 0x1059ae348>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memv = memoryview(numbers)\n",
    "memv_oct = memv.cast('B') # no copy\n",
    "memv_oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[254, 255, 255, 255, 0, 0, 1, 0, 2, 0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(memv_oct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can dive into a structure. Once we have read the data once from a file (get it at https://www.dropbox.com/s/e4rleswrcgwt3hp/pcanim.gif?dl=0 ), it does not need to be recopied just to inspect it. Here we use the struct module, which is useful to share data with C like systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'GIF89a\\xe8\\x03\\x90\\x01'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import struct\n",
    "fmt = '<3s3sHH'#little endian, 2 seq 3 bytes, 2 unsigned shorts\n",
    "with open(\"pcanim.gif\", 'rb') as fd:\n",
    "    readit = fd.read()\n",
    "    msg = memoryview(readit) #no copy\n",
    "header = msg[:10] # 10 byte view, no copy, imagine the savings\n",
    "bytes(header)# finally a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'GIF', b'89a', 1000, 400)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct.unpack(fmt, header)#type/version/width/height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### indexing and slicing\n",
    "\n",
    "As we saw above, **memoryviews support indexing and slicing**. Multidimensional, even."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(111, <memory at 0x1059ae048>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = b'Hello world'\n",
    "print(type(bs))\n",
    "memv = memoryview(bs)\n",
    "memv[4], memv[2:4] #the second is a view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11,), (1,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memv.shape, memv.strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "zerosmv = memoryview(np.zeros((10, 11, 12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 11, 12), (1056, 96, 8), 3, 8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zerosmv.shape, zerosmv.strides, zerosmv.ndim, zerosmv.itemsize #c contigous, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " Memoryviews, just like numpy arrays can be multi-dimensional, and come with some of the properties numpy arrays have..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### mutable vs immutable data structures\n",
    "\n",
    "bytestrings, also known as **bytes** such as `b'hello'` are read-only in python, and the corresponding memoryviews are too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memoryview, bytes)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(msg), type(readit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bytes' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-e0404bf63a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreadit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'bytes' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "readit[0]=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot modify read-only memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-a6dfc5182e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot modify read-only memory"
     ]
    }
   ],
   "source": [
    "msg[0]=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "memoryviews follow the \"read-only\" status of bytes.\n",
    "\n",
    "**bytearrays** as opposed to bytes, are read-write, which leads to being able to pre-allocate a \"buffer\", get a memoryview on it, and use the slice syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "with open(\"pcanim.gif\", 'rb') as fd:\n",
    "    data = bytearray(os.path.getsize(\"pcanim.gif\"))\n",
    "    fd.readinto(data)\n",
    "mv = memoryview(data)\n",
    "mv[0]=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This gives us a way to do something we couldn't achieve by any other means - read from a file (or receive from a socket) directly into the middle of some existing buffer\n",
    "\n",
    "```python\n",
    "buf = bytearray(...) # pre-allocated to the needed size\n",
    "mv = memoryview(buf)\n",
    "numread = f.readinto(mv[some_offset:])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### the buffer protocol\n",
    "\n",
    "Using memoryviews in this fashion\n",
    "is how Python objects expose raw byte buffers (arrays), to both C/cython as well as python. This is called the buffer protocol, and is specified at the C level. Its out of our scope, but google it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Kurt Smith, in the O-Reilly cython book:\n",
    ">The new buffer protocol is a C-level protocol. The new buffer protocolâ€™s most important feature is its ability to represent the same underlying data in different ways. It allows NumPy arrays, several Python built-in types, and Cython-level array-like objects to share the same data without copying. With Cython, we can also easily extend the buffer protocol to work with data coming from an external library.\n",
    "\n",
    "These are python types you can create a memoryview from:\n",
    "\n",
    "- ndarray, py2 string, py3 unicode\n",
    "- bytes and bytearray types, array.array, ctypes arrays\n",
    "- third party, like in PIL\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
